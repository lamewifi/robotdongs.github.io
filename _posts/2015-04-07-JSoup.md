---
layout: post
title: "Using JSoup to scrape a Webpage."
date: 2015-04-07
---


##BackGround:
The first major version of my Installment billing calculator worked fine, However it is a huge pain to update and maintain. In its current form all pricing information is hard-coded into the app. When prices and phone availability change I  have to manually update the app with the new information. I needed a simple way to automatically update the relevant pricing information for my app. 

After doing a little bit of research I came across JSoup. JSoup is a third party library that provides a somewhat simple API for extracting, reading or changing data contained in HTML documents using DOM, CSS and "JQuery-like methods".


JSoup will allow me to scrape the relevant pricing information from each respective carrier’s website, I could then store this information on online and use Java's built in URL class with a Scanner object to read the contents of the file(s) and update the relevant variables in my app.

[Get JSoup Here](http://jsoup.org/)


I figured today I'd provide a simple tutorial just to show how easy it is to use JSoup. This will be a very sweet and short simple program that will give us the vote count for all the links on the front page of reddit, subreddit the link was submitted and the username of the submitter. 


##Getting Started with JSoup:

Once you’ve got JSoup installed  open up your favorite IDE or text editor, and lets get started. 

###Import Classes and Exceptions: 


Import these classes and exceptions.
	1.	import org.jsoup.Jsoup;
	2.	import org.jsoup.nodes.Document;
	2.	import org.jsoup.select.Elements;
	3.	import org.jsoup.select.Element;
	4.	import java.io.IOException;


Once you've got your import statements we're going to declare a Document variable and Elements variable. Assuming you've created your main method your code should look like this:

-------------------------------------------------------------------------------

~~~Java

import org.jsoup.Jsoup;
import org.jsoup.nodes.Document;
import org.jsoup.select.Elements;
import org.jsoup.select.Element;
import java.io.IOException;

public class main{

private static Elements elements;

  private static Document doc;
	
  public static void main(String args[]){

   }//End main method

}//End class

~~~

-------------------------------------------------------------------------------

In your main method add a **try...catch** statement and catch an IOException leaving the try block blank for now. In addition to the try..catch statment declare 3 variables. Two Elements variables, and a Document Variable. Your code should now look like this:

-------------------------------------------------------------------------------

~~~java
package soupTest;

import org.jsoup.Jsoup;
import org.jsoup.nodes.Document;
import org.jsoup.select.Elements;
import org.jsoup.select.Element;
import java.io.IOException;

 public class main {

	private static Document doc;
	private static Elements getRawElements
    private static Elements getScore;
    private static Elementss getRawUser;
    private static Elements getFinalUser;
	
    public static void main(String args[]){

		try{

			}catch(IOException IOE){
	
		}//End try...catch statement
	 
	 }//End main
    
}//End class

~~~

-------------------------------------------------------------------------------

##What we have so far...


The **Document** class is used to parse (for the lack of a better term) an HTML document similar to a web-browser. The <a href="http://jsoup.org/apidocs/org/jsoup/nodes/Document.html">Document</a> class only has one constructor and only accepts one String argument. For our purposes this string will be a URL to a web-page, but it can also be directory location of a locally hosted HTML file or fragment.



The <a href="http://jsoup.org/apidocs/org/jsoup/select/Elements.html"> Elements </a> class is what you’ll use to help scrape the web-page, sort-of-like an ArrayList, in that an Elements object will hold a bunch of stuff. We ‘construct’ our Elements object with using the Document object (‘doc) we created earlier. 


In your main method(inside of the try statement) add the following code:


-------------------------------------------------------------------------------
~~~Java
	doc = JSoup.connect("http://www.reddit.com").get();
	getRawElements = doc.select(“div”);
	System.out.println(getRawElements.tostring);
~~~

-------------------------------------------------------------------------------

Run the code now and you should get an output with a lot of text. What you're seeing are the various text attributes of all the various "Div" tags in the html doccument reddit.com

###Getting more selective

Using the **select method** from the Document class, we are creating an Elements Object (elements) that will contain all of the "div" HTML elements present in the HTML document (reddit.com). 

Obviously this won't really work for us. It just returns the raw HTML of the front page. 
We'll have to run a few select statements to get what we want But before we can make our element selection more relevant we have to know what to select for. Thankfully most modern browsers can really help us out here. In chrome if I go to reddit.com, move my mouse over a link vote total, right-click and inspect element I can usually find what I'm looking for. 
 
 
![img3](/media/2015-04-07-JSoup/redditIE.png)




Do you see where it is highlighted towards the top of the image? "Div.score.unvoted" that's what we're looking for. We can use the above div class to help refine our element search. Change the current getFinalElements = doc.select("div"); from "div" to: 

-------------------------------------------------------------------------------

~~~Java

getRawElements = doc.select("div[class=score unvoted]")

~~~ 

-------------------------------------------------------------------------------

The use of element[class=name] allows us to select all the elements within all of the div tags that belong to the "score unvoted" class. We still need to refine our element search a little more before we can get our desired results. 

If you look at the reddit page source again you'll notice that the links we want are actually within a div tag with an id of "siteTable". Pulling our "div.score.unvoted" selection from all the elements contained in the div tag with the ID of "siteTable" should only provide us links with actual scores eliminating  most of the "•" we got for some of the links. I'm sure I could find the exact div tag class, ID and attributes to only get the scores but using an **if...else** statement would be a little faster for removing the last "•" being pulled than searching for that one specific tag.

We'll use getFinalElements

-------------------------------------------------------------------------------

~~~Java

getFinalElements = getRawElements.select("div#siteTable"); 

~~~

-------------------------------------------------------------------------------

The #siteTable indicates the ID name of the div tag we're looking for. There are a lot of diffrent types of selectors you can find a lot of them [Here.](http://jsoup.org/cookbook/extracting-data/selector-syntax) Your code should now look something similar to this:

-------------------------------------------------------------------------------

~~~Java 

import org.jsoup.Jsoup;
import org.jsoup.nodes.Document;
import org.jsoup.select.Elements;
import org.jsoup.select.Element;
import java.io.IOException;

 public class main {

	private static Document doc;
	private static Elements getRawElements
    private static Elements getScore;
    private static Elementss getRawUser;
    private static Elements getFinalUser;
	
    public static void main(String args[]){
		Document doc;
        Elements getUserName;
        Elements getFinalUserNames;
        Elements getRawElements;
        Elements getFinalElements;
		try{
       		 doc = Jsoup.connect("http://www.reddit.com").get();
            getRawElements = doc.select("div#siteTable");
            getFinalElements = getRawElements.select("div[class=score unvoted]");
				System.out.println(getFinalElements.text());
			}catch(IOException IOE){
	
		}//End try...catch statement
	 
	 }//End main
    
}//End class

~~~
-------------------------------------------------------------------------------

To finish with the vote counts we're going to add a for statement with an **if** statement nested inside. 

-------------------------------------------------------------------------------

~~~Java
	   for (int i = 0; i < (getFinalElements.size());i++){
                if ((getFinalElements.get(i).text().length() > 1)){
                    System.out.println(getFinalElements.get(i).text());
                }
~~~

-------------------------------------------------------------------------------

We know the votes on the front page will always have at least more than 9 votes, by requiring  the string length to be greater than 1 character in length will insure that we only get the vote total from front page links. 

We could stop here, but what if you want to know the username and subreddit for the link? 

To do that we'll need to select diffrent elements. We need to select a "p" tag of class "tagline" and the text of an "a" tag with a "[href] attribute. We can use the getUserNAme and getFinalUserName variables to store the selections.


-------------------------------------------------------------------------------
~~~Java
		 getUserName = getRawElements.select("p[class=tagline");
            getFinalUserNames = getUserName.select("a[href]");
~~~
-------------------------------------------------------------------------------


I'm selecing all the "p" tags of the "tagline" class that are **only** contained within the div tag with the ID of "siteTable" (which are now stored in variable getRawElements).  From that selection we want to grab the text of the Href attributes that are within the "p" tag we just selected.

Now we've got to "sync" the names and subreddits that we've scraped with the correct vote counts, all we need is a enhanced for loop and a single integer variable.



-------------------------------------------------------------------------------

~~~Java
		int count = 0;
    for(Element x: getFinalElements){
   		 System.out.println("Votes: " + x.text()); //Will print the vote counts.
   		 System.out.println("Sub-reddit: "getFinalUserNames.get(count).text());
	count++;
		System.out.println("UserName: "getFinalUserNames.get(count).text());
	count++;    
		   
    }
~~~

-------------------------------------------------------------------------------


We couldn't just loop through the lists like we normally would for display, because we've got to place two strings (getFinalUserNames) between each vote count (x), all the more challenging when the username and subreddit are stored in even/odd index values (meaning I can't rely on "i" in the loop.)  I'm sure I could have created a more elgant solution, but this way was this way was certainly the fastest. 




###Your Final Code:

-------------------------------------------------------------------------------

~~~Java
public static void main(String args[]){
        Document doc;
        Elements getUserName;
        Elements getFinalUserNames;
        Elements getRawElements;
        Elements getFinalElements;
        try{
            doc = Jsoup.connect("http://www.reddit.com").get();
            getRawElements = doc.select("div#siteTable");
            getFinalElements = getRawElements.select("div[class=score unvoted]");
            getUserName = getRawElements.select("p[class=tagline");
            getFinalUserNames = getUserName.select("a[href]");
            int count = 0;

          for (Element x: getFinalElements){
                System.out.println("Votes: " + x.text());
                System.out.println("SubReddit: " + getFinalUserNames.get(count).text());
                count++;
                System.out.println("UserName: " + getFinalUserNames.get(count).text());
                count++;
            }

        }catch (IOException ioe){
        }
    }//End Main

~~~

-------------------------------------------------------------------------------


I've barely touched on the surface when it comes to using JSoup Library, but Hopefully I've given you enough of a start to give you some ideas of what you can do with the libary. 
